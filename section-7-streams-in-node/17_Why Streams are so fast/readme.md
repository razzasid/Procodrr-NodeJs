# âš¡ Why Streams Are So Fast?

When dealing with **large datasets**, Node.js **Streams** are much faster and memory-friendly compared to traditional methods like `appendFileSync` or `writeFileSync`.

## ğŸ” How Streams Work Internally

Streams optimize file writing by reducing overhead.

âœ… **File opened only once**  
âœ… **Internal buffer in RAM** â†’ handles data in small chunks  
âœ… **Continuous writes** â†’ keeps pushing data without reopening the file  
âœ… **File closed only once** â†’ after calling `.end()`

### ğŸ“Œ **In short:**

```
Open file â†’ Efficient multiple writes â†’ Close file
```

This means fewer disk operations and faster performance.

## ğŸ¢ Why `appendFileSync` / `writeFileSync` Are Slower

When you use `appendFileSync` or `writeFileSync` inside a loop:

1. ğŸ“‚ Open the file
2. ğŸ’¾ Write the data directly to disk
3. ğŸšª Close the file

This repeats **thousands of times** for big loops, which:

* Blocks the event loop (because it's synchronous).
* Wastes time reopening and closing the file each time.
* Causes major slowdowns compared to streaming.

## ğŸ“Š Comparison

| Feature | Streams (`createWriteStream`) | `appendFileSync` / `writeFileSync` |
|---------|------------------------------|-----------------------------------|
| File open/close calls | Once (open at start, close at end) | Every loop iteration |
| Writing style | Buffered (chunks in memory, flushed in bulk) | Direct disk writes (small pieces) |
| Blocking or Non-blocking | Non-blocking (async) | Blocking (sync) |
| Speed on large data | Very fast | Very slow |
| Memory usage | Efficient (buffered) | High (many disk operations) |

## âœ… **Takeaway:** Use **Streams** when working with large files. They save time, reduce memory use, and keep your program responsive.